{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "churn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1X-8oQ0l2NFhy0VsZYEtoLY356DIoKvkg",
      "authorship_tag": "ABX9TyNw8BpM7OfV2i0nsnjP50l+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/E-wave112/ml_proj1/blob/master/churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lSBfSeIhgW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2e7f82a8-0ee2-43ce-b4ae-31933f6a6747"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report,recall_score,precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from statistics import mean\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Train (1).csv\")\n",
        "df.drop([\"user_id\"],1,inplace=True)\n",
        "\n",
        "A = df[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Z = df[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Z = Z.apply(labelencoder.fit_transform)\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(Z)\n",
        "onelabel = enc.transform(Z).toarray()\n",
        "\n",
        "df[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Z\n",
        "'''\n",
        "for i,j,k,l,m,n,o,p,q,r in zip(df['MONTANA'],df[\"FREQUENCY_RECH\"],df[\"REVENUE\"],\n",
        "                             df[\"ARPU_SEGMENT\"],df[\"FREQUENCE\"],df[\"DATA_VOLUME\"],\n",
        "                             df[\"ON_NET\"],df[\"ORANGE\"],df[\"FREQ_TOP_PACK\"],df[\"TIGO\"]):\n",
        "                             '''\n",
        "\n",
        "df['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "df.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "#df.hist(bins=50,figsize = (15,15))\n",
        "C= df.drop([\"CHURN\"],1)\n",
        "D = df[\"CHURN\"]\n",
        "#print(df.info())\n",
        "\n",
        "##applying random forest classifier\n",
        "df2 = pd.read_csv(\"/content/drive/My Drive/Test (1).csv\")\n",
        "\n",
        "P = df2[\"user_id\"]\n",
        "\n",
        "df2.drop([\"user_id\"],1,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "A = df2[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df2[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Y = df2[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Y = Y.apply(labelencoder.fit_transform)\n",
        "\n",
        "enc2 = OneHotEncoder()\n",
        "enc2.fit(Y)\n",
        "onelabel2 = enc.transform(Y).toarray()\n",
        "\n",
        "df2[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Y\n",
        "df2['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df2[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df2[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df2[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df2[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df2[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df2[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df2[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df2[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df2[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "\n",
        "df2.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "\n",
        "\n",
        "print(df2.shape)\n",
        "'''\n",
        "param_grid = {\n",
        "    \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
        "    \"n_estimators\":[100,200,300,400,500,600,700,800,900,1000],\n",
        "    \"criterion\":[\"gini\", \"entropy\"],\n",
        "    \"min_samples_split\":[2,4,6],\n",
        "    \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] \n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=30),param_grid,refit=True,verbose=2,n_jobs=-1)\n",
        "grid.fit(C,D)\n",
        "print(grid.best_estimator_)\n",
        "'''\n",
        "rdf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=None, oob_score=False, random_state=23,\n",
        "                       verbose=0, warm_start=False)\n",
        "rdf.fit(C,D)\n",
        "\n",
        "y_pred = rdf.predict_proba(df2)\n",
        "print(len(y_pred))\n",
        "\n",
        "\n",
        "df3 = pd.read_csv(\"/content/drive/My Drive/sample_submission.csv\")\n",
        "print(df3.shape)\n",
        "df3[\"CHURN\"] = y_pred\n",
        "df3.to_csv(\"/content/drive/My Drive/zindifinal.csv\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 14)\n",
            "100000\n",
            "(100000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqdCazWWp6Oh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c05ad87-86de-48d3-b2eb-8ddb8ceb26d4"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report,recall_score,precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from statistics import mean\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Train (1).csv\")\n",
        "df.drop([\"user_id\"],1,inplace=True)\n",
        "\n",
        "A = df[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Z = df[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Z = Z.apply(labelencoder.fit_transform)\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(Z)\n",
        "onelabel = enc.transform(Z).toarray()\n",
        "\n",
        "df[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Z\n",
        "'''\n",
        "for i,j,k,l,m,n,o,p,q,r in zip(df['MONTANA'],df[\"FREQUENCY_RECH\"],df[\"REVENUE\"],\n",
        "                             df[\"ARPU_SEGMENT\"],df[\"FREQUENCE\"],df[\"DATA_VOLUME\"],\n",
        "                             df[\"ON_NET\"],df[\"ORANGE\"],df[\"FREQ_TOP_PACK\"],df[\"TIGO\"]):\n",
        "                             '''\n",
        "\n",
        "df['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "df.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "#df.hist(bins=50,figsize = (15,15))\n",
        "C,D = df.iloc[:,:-1],df.iloc[:,-1]\n",
        "#print(df.info())\n",
        "\n",
        "data_dmatrix = xgb.DMatrix(data=C,label=D)\n",
        "\n",
        "##applying random forest classifier\n",
        "df2 = pd.read_csv(\"/content/drive/My Drive/Test (1).csv\")\n",
        "\n",
        "P = df2[\"user_id\"]\n",
        "\n",
        "df2.drop([\"user_id\"],1,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "A = df2[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df2[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Y = df2[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Y = Y.apply(labelencoder.fit_transform)\n",
        "\n",
        "enc2 = OneHotEncoder()\n",
        "enc2.fit(Y)\n",
        "onelabel2 = enc.transform(Y).toarray()\n",
        "\n",
        "df2[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Y\n",
        "df2['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df2[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df2[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df2[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df2[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df2[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df2[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df2[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df2[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df2[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "\n",
        "df2.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "\n",
        "print(df2.info())\n",
        "#print(df2.shape)\n",
        "'''\n",
        "param_grid = {\n",
        "    \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
        "    \"n_estimators\":[100,200,300,400,500,600,700,800,900,1000],\n",
        "    \"criterion\":[\"gini\", \"entropy\"],\n",
        "    \"min_samples_split\":[2,4,6],\n",
        "    \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] \n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=30),param_grid,refit=True,verbose=2,n_jobs=-1)\n",
        "grid.fit(C,D)\n",
        "print(grid.best_estimator_)\n",
        "'''\n",
        "\n",
        "xg_reg = xgb.XGBClassifier()\n",
        "xg_reg.fit(C,D)\n",
        "y_pred = xg_reg.predict_proba(df2)\n",
        "print(y_pred[1:100])\n",
        "\n",
        "#new_file = pd.DataFrame({\"user_id\":P, \"CHURN\":y_pred})\n",
        "df4 = pd.read_csv(\"/content/drive/My Drive/sample_submission.csv\")\n",
        "print(df3.shape)\n",
        "df4[\"CHURN\"] = y_pred\n",
        "df4.to_csv(\"/content/drive/My Drive/zindifinal3.csv\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 14 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   REGION          100000 non-null  int64  \n",
            " 1   TENURE          100000 non-null  int64  \n",
            " 2   MONTANT         100000 non-null  float64\n",
            " 3   FREQUENCE_RECH  100000 non-null  float64\n",
            " 4   REVENUE         100000 non-null  float64\n",
            " 5   ARPU_SEGMENT    100000 non-null  float64\n",
            " 6   FREQUENCE       100000 non-null  float64\n",
            " 7   DATA_VOLUME     100000 non-null  float64\n",
            " 8   ON_NET          100000 non-null  float64\n",
            " 9   ORANGE          100000 non-null  float64\n",
            " 10  TIGO            100000 non-null  float64\n",
            " 11  REGULARITY      100000 non-null  int64  \n",
            " 12  TOP_PACK        100000 non-null  int64  \n",
            " 13  FREQ_TOP_PACK   100000 non-null  float64\n",
            "dtypes: float64(10), int64(4)\n",
            "memory usage: 10.7 MB\n",
            "None\n",
            "[[3.71026278e-01 6.28973722e-01]\n",
            " [8.81190717e-01 1.18809275e-01]\n",
            " [9.97716069e-01 2.28392752e-03]\n",
            " [9.99505520e-01 4.94452368e-04]\n",
            " [7.53184378e-01 2.46815637e-01]\n",
            " [9.79413927e-01 2.05860697e-02]\n",
            " [4.40893531e-01 5.59106469e-01]\n",
            " [9.99135315e-01 8.64688947e-04]\n",
            " [9.59232152e-01 4.07678299e-02]\n",
            " [9.94090199e-01 5.90979680e-03]\n",
            " [9.78912771e-01 2.10872516e-02]\n",
            " [9.98426080e-01 1.57389732e-03]\n",
            " [3.96189153e-01 6.03810847e-01]\n",
            " [9.97462869e-01 2.53711478e-03]\n",
            " [4.40893531e-01 5.59106469e-01]\n",
            " [9.91645157e-01 8.35485384e-03]\n",
            " [9.99465644e-01 5.34328807e-04]\n",
            " [9.97672856e-01 2.32715579e-03]\n",
            " [2.29191124e-01 7.70808876e-01]\n",
            " [9.97090816e-01 2.90917791e-03]\n",
            " [4.78495181e-01 5.21504819e-01]\n",
            " [5.11830568e-01 4.88169432e-01]\n",
            " [9.99126792e-01 8.73196637e-04]\n",
            " [8.46674919e-01 1.53325111e-01]\n",
            " [9.99179780e-01 8.20233719e-04]\n",
            " [6.92278028e-01 3.07722002e-01]\n",
            " [2.29191124e-01 7.70808876e-01]\n",
            " [9.98330653e-01 1.66937080e-03]\n",
            " [9.94291961e-01 5.70806116e-03]\n",
            " [9.98075902e-01 1.92410208e-03]\n",
            " [9.44646835e-01 5.53531647e-02]\n",
            " [9.86883700e-01 1.31163131e-02]\n",
            " [5.14511049e-01 4.85488951e-01]\n",
            " [9.99047041e-01 9.52975475e-04]\n",
            " [9.87588584e-01 1.24113997e-02]\n",
            " [2.29191124e-01 7.70808876e-01]\n",
            " [3.01001549e-01 6.98998451e-01]\n",
            " [9.82584119e-01 1.74158961e-02]\n",
            " [3.96189153e-01 6.03810847e-01]\n",
            " [3.42250943e-01 6.57749057e-01]\n",
            " [9.99165595e-01 8.34424049e-04]\n",
            " [2.29191124e-01 7.70808876e-01]\n",
            " [9.96308923e-01 3.69107816e-03]\n",
            " [9.99457479e-01 5.42520953e-04]\n",
            " [9.01492357e-01 9.85076129e-02]\n",
            " [8.79929245e-01 1.20070755e-01]\n",
            " [8.82296503e-01 1.17703475e-01]\n",
            " [9.99411762e-01 5.88234689e-04]\n",
            " [2.29191124e-01 7.70808876e-01]\n",
            " [9.82480466e-01 1.75195355e-02]\n",
            " [9.99361038e-01 6.38966099e-04]\n",
            " [9.98138428e-01 1.86160160e-03]\n",
            " [9.95810866e-01 4.18912061e-03]\n",
            " [8.29712927e-01 1.70287058e-01]\n",
            " [9.77247894e-01 2.27521099e-02]\n",
            " [8.18437755e-01 1.81562260e-01]\n",
            " [9.99352217e-01 6.47770998e-04]\n",
            " [9.98355031e-01 1.64496247e-03]\n",
            " [9.91323829e-01 8.67619924e-03]\n",
            " [9.63136673e-01 3.68633531e-02]\n",
            " [9.98712301e-01 1.28768932e-03]\n",
            " [9.99202788e-01 7.97190936e-04]\n",
            " [2.29191124e-01 7.70808876e-01]\n",
            " [7.98102379e-01 2.01897606e-01]\n",
            " [9.99287367e-01 7.12617126e-04]\n",
            " [8.24570835e-01 1.75429180e-01]\n",
            " [9.97680545e-01 2.31943885e-03]\n",
            " [9.86146927e-01 1.38530908e-02]\n",
            " [8.48148108e-01 1.51851878e-01]\n",
            " [9.96594965e-01 3.40500940e-03]\n",
            " [2.29191124e-01 7.70808876e-01]\n",
            " [9.87052679e-01 1.29473442e-02]\n",
            " [6.83488488e-01 3.16511482e-01]\n",
            " [9.95978415e-01 4.02159756e-03]\n",
            " [9.99175787e-01 8.24231131e-04]\n",
            " [2.66846478e-01 7.33153522e-01]\n",
            " [9.99474227e-01 5.25796320e-04]\n",
            " [9.98404324e-01 1.59566675e-03]\n",
            " [9.81355846e-01 1.86441541e-02]\n",
            " [9.99036849e-01 9.63148952e-04]\n",
            " [4.89394307e-01 5.10605693e-01]\n",
            " [9.99373138e-01 6.26860012e-04]\n",
            " [9.99117553e-01 8.82438559e-04]\n",
            " [9.57027793e-01 4.29721773e-02]\n",
            " [3.23067784e-01 6.76932216e-01]\n",
            " [9.94872630e-01 5.12735220e-03]\n",
            " [9.98440504e-01 1.55948021e-03]\n",
            " [9.98048782e-01 1.95124559e-03]\n",
            " [8.14277411e-01 1.85722604e-01]\n",
            " [9.89975750e-01 1.00242589e-02]\n",
            " [8.15144300e-01 1.84855714e-01]\n",
            " [9.99304533e-01 6.95484574e-04]\n",
            " [9.95643914e-01 4.35611326e-03]\n",
            " [9.96554852e-01 3.44513962e-03]\n",
            " [3.96189153e-01 6.03810847e-01]\n",
            " [7.48786390e-01 2.51213610e-01]\n",
            " [9.99034941e-01 9.65048559e-04]\n",
            " [9.99414980e-01 5.85005560e-04]\n",
            " [3.23067784e-01 6.76932216e-01]]\n",
            "(100000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8ZCwLjW-G7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7271b30-3e6b-46bd-fc2f-2eb6a14ecd2a"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report,recall_score,precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from statistics import mean\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Train (1).csv\")\n",
        "df.drop([\"user_id\"],1,inplace=True)\n",
        "f = df.columns\n",
        "A = df[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Z = df[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Z = Z.apply(labelencoder.fit_transform)\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(Z)\n",
        "onelabel = enc.transform(Z).toarray()\n",
        "\n",
        "df[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Z\n",
        "\n",
        "df['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "df.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "f = df.columns\n",
        "#df.hist(bins=50,figsize = (15,15))\n",
        "standardscale = MinMaxScaler()\n",
        "df = standardscale.fit_transform(df)\n",
        "df = pd.DataFrame(df, columns=f)\n",
        "C,D = df.iloc[:,:-1],df.iloc[:,-1]\n",
        "\n",
        "#print(df.info())\n",
        "\n",
        "##applying random forest classifier\n",
        "df2 = pd.read_csv(\"/content/drive/My Drive/Test (1).csv\")\n",
        "\n",
        "P = df2[\"user_id\"]\n",
        "\n",
        "df2.drop([\"user_id\"],1,inplace=True)\n",
        "\n",
        "\n",
        "A = df2[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df2[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Y = df2[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Y = Y.apply(labelencoder.fit_transform)\n",
        "\n",
        "enc2 = OneHotEncoder()\n",
        "enc2.fit(Y)\n",
        "onelabel2 = enc.transform(Y).toarray()\n",
        "\n",
        "df2[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Y\n",
        "df2['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df2[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df2[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df2[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df2[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df2[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df2[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df2[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df2[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df2[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "\n",
        "df2.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "\n",
        "#print(df2.info())\n",
        "#print(df2.shape)\n",
        "'''\n",
        "param_grid = {\n",
        "     \"penalty\":[ 'l2', 'elasticnet', 'none'],\n",
        "    \"C\":[0.01, 0.1, 1],\n",
        "    \"solver\":[ 'sag', 'saga'],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(random_state=30,max_iter=400),param_grid,refit=True,verbose=2)\n",
        "grid.fit(C,D)\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "'''\n",
        "lg_reg = LogisticRegression(random_state=30,C=0.01, penalty=\"l2\", solver=\"sag\")\n",
        "lg_reg.fit(C,D)\n",
        "y_pred = lg_reg.predict_proba(df2)\n",
        "print(y_pred[1:100])\n",
        "\n",
        "#new_file = pd.DataFrame({\"user_id\":P, \"CHURN\":y_pred})\n",
        "df4 = pd.read_csv(\"/content/drive/My Drive/sample_submission.csv\")\n",
        "print(df4.shape)\n",
        "df4[\"CHURN\"] = y_pred\n",
        "df4.to_csv(\"/content/drive/My Drive/zindifinal350.csv\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [9.60855527e-01 3.91444727e-02]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.10294196e-33]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.05062417e-65]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.84945392e-10 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 3.25329223e-15]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 7.48710608e-83]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.70072414e-70]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 3.36933962e-58]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.11022302e-15 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]]\n",
            "(100000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdkJL8hBkEJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd4272b6-b290-43a0-8d83-0d1b341ae5e2"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report,recall_score,precision_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Train (1).csv\")\n",
        "df.drop([\"user_id\"],1,inplace=True)\n",
        "\n",
        "A = df[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Z = df[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Z = Z.apply(labelencoder.fit_transform)\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(Z)\n",
        "onelabel = enc.transform(Z).toarray()\n",
        "\n",
        "df[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Z\n",
        "\n",
        "df['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "df.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "#df.hist(bins=50,figsize = (15,15))\n",
        "f = df.columns\n",
        "minmax = MinMaxScaler()\n",
        "minmax.fit_transform(df)\n",
        "df = pd.DataFrame(df,columns=f)\n",
        "C,D = df.iloc[:,:-1],df.iloc[:,-1]\n",
        "#print(df.info())\n",
        "\n",
        "##applying SGD CLASSIFIER\n",
        "df2 = pd.read_csv(\"/content/drive/My Drive/Test (1).csv\")\n",
        "\n",
        "P = df2[\"user_id\"]\n",
        "\n",
        "df2.drop([\"user_id\"],1,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "A = df2[\"TOP_PACK\"]\n",
        "A = A.fillna(\"a\",inplace=True)\n",
        "B = df2[\"REGION\"]\n",
        "B = B.fillna(\"b\",inplace=True)\n",
        "\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "Y = df2[[\"MRG\",\"TENURE\",\"REGION\",\"TOP_PACK\"]]\n",
        "\n",
        "Y = Y.apply(labelencoder.fit_transform)\n",
        "\n",
        "enc2 = OneHotEncoder()\n",
        "enc2.fit(Y)\n",
        "onelabel2 = enc.transform(Y).toarray()\n",
        "\n",
        "df2[[\"MRG\", \"TENURE\", \"REGION\", 'TOP_PACK']] = Y\n",
        "df2['MONTANT'].fillna(np.mean(df['MONTANT']),inplace=True)\n",
        "df2[\"FREQUENCE_RECH\"].fillna(np.mean(df[\"FREQUENCE_RECH\"]),inplace=True)\n",
        "df2[\"REVENUE\"].fillna(np.mean(df[\"REVENUE\"]),inplace=True)\n",
        "df2[\"ARPU_SEGMENT\"].fillna(np.mean(df[\"ARPU_SEGMENT\"]),inplace=True)\n",
        "df2[\"FREQUENCE\"].fillna(np.mean(df[\"FREQUENCE\"]),inplace=True)\n",
        "df2[\"DATA_VOLUME\"].fillna(np.mean(df[\"DATA_VOLUME\"]),inplace=True)\n",
        "df2[\"ON_NET\"].fillna(np.mean(df[\"ON_NET\"]),inplace=True)\n",
        "df2[\"ORANGE\"].fillna(np.mean(df[\"ORANGE\"]),inplace=True)\n",
        "df2[\"FREQ_TOP_PACK\"].fillna(np.mean(df[\"FREQ_TOP_PACK\"]),inplace=True)\n",
        "df2[\"TIGO\"].fillna(np.mean(df[\"TIGO\"]),inplace=True)\n",
        "\n",
        "\n",
        "df2.drop([\"ZONE1\",\"ZONE2\",'MRG'],1,inplace=True)\n",
        "\n",
        "#print(df2.info())\n",
        "#print(df2.shape)\n",
        "'''\n",
        "param_grid = {\n",
        "     \"penalty\":[ 'l2', 'elasticnet', 'none'],\n",
        "    \"epsilon\":[0.01, 0.1, 1],\n",
        "    'alpha':[0.0001,0.001,0.01,0.1,1]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SGDClassifier(random_state=30,loss='log'),param_grid,refit=True,verbose=2)\n",
        "grid.fit(C,D)\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "\n",
        "'''\n",
        "lg_reg = SGDClassifier(random_state=30,alpha=0.1,epsilon=0.01,loss='log', penalty=\"elasticnet\")\n",
        "lg_reg.fit(C,D)\n",
        "y_pred = lg_reg.predict_proba(df2)\n",
        "print(y_pred[1:100])\n",
        "\n",
        "#new_file = pd.DataFrame({\"user_id\":P, \"CHURN\":y_pred})\n",
        "df4 = pd.read_csv(\"/content/drive/My Drive/sample_submission.csv\")\n",
        "print(df4.shape)\n",
        "df4[\"CHURN\"] = y_pred\n",
        "df4.to_csv(\"/content/drive/My Drive/zindifinalsette.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.82581884e-01 7.17418116e-01]\n",
            " [9.98515794e-01 1.48420580e-03]\n",
            " [9.99998291e-01 1.70923653e-06]\n",
            " [1.00000000e+00 4.88255585e-17]\n",
            " [9.88266855e-01 1.17331454e-02]\n",
            " [9.88962927e-01 1.10370730e-02]\n",
            " [4.02473853e-01 5.97526147e-01]\n",
            " [9.99999941e-01 5.94588180e-08]\n",
            " [9.99999295e-01 7.05495307e-07]\n",
            " [9.99828900e-01 1.71099731e-04]\n",
            " [9.96438758e-01 3.56124153e-03]\n",
            " [9.99999138e-01 8.61740450e-07]\n",
            " [3.39969714e-01 6.60030286e-01]\n",
            " [9.99999137e-01 8.62986325e-07]\n",
            " [4.02473853e-01 5.97526147e-01]\n",
            " [9.99878844e-01 1.21155876e-04]\n",
            " [9.99999973e-01 2.70616712e-08]\n",
            " [9.99999494e-01 5.05943025e-07]\n",
            " [2.31483804e-01 7.68516196e-01]\n",
            " [9.99994921e-01 5.07879603e-06]\n",
            " [3.79812129e-01 6.20187871e-01]\n",
            " [4.68315852e-01 5.31684148e-01]\n",
            " [9.99999997e-01 2.82225538e-09]\n",
            " [9.99596138e-01 4.03862204e-04]\n",
            " [9.99994266e-01 5.73381966e-06]\n",
            " [8.52069088e-01 1.47930912e-01]\n",
            " [2.31483804e-01 7.68516196e-01]\n",
            " [9.99997487e-01 2.51308990e-06]\n",
            " [9.99931362e-01 6.86379074e-05]\n",
            " [9.99997358e-01 2.64223639e-06]\n",
            " [9.80209877e-01 1.97901234e-02]\n",
            " [9.89034794e-01 1.09652063e-02]\n",
            " [4.02473853e-01 5.97526147e-01]\n",
            " [9.99999997e-01 3.38690671e-09]\n",
            " [9.99120379e-01 8.79621329e-04]\n",
            " [2.31483804e-01 7.68516196e-01]\n",
            " [2.82581884e-01 7.17418116e-01]\n",
            " [9.98945315e-01 1.05468520e-03]\n",
            " [3.39969714e-01 6.60030286e-01]\n",
            " [2.82581884e-01 7.17418116e-01]\n",
            " [9.99999556e-01 4.43732397e-07]\n",
            " [2.31483804e-01 7.68516196e-01]\n",
            " [9.99965255e-01 3.47448893e-05]\n",
            " [9.99999998e-01 2.49856697e-09]\n",
            " [9.98009893e-01 1.99010684e-03]\n",
            " [6.42000920e-01 3.57999080e-01]\n",
            " [9.99991016e-01 8.98415996e-06]\n",
            " [9.99999995e-01 5.39941335e-09]\n",
            " [2.31483804e-01 7.68516196e-01]\n",
            " [9.45166580e-01 5.48334203e-02]\n",
            " [1.00000000e+00 1.85866385e-12]\n",
            " [9.99999494e-01 5.06308932e-07]\n",
            " [9.99755229e-01 2.44771413e-04]\n",
            " [9.99569891e-01 4.30108775e-04]\n",
            " [9.92355336e-01 7.64466378e-03]\n",
            " [9.09847937e-01 9.01520628e-02]\n",
            " [9.99999938e-01 6.22167010e-08]\n",
            " [9.99998685e-01 1.31547425e-06]\n",
            " [9.96955132e-01 3.04486786e-03]\n",
            " [8.20398116e-01 1.79601884e-01]\n",
            " [9.99998621e-01 1.37900204e-06]\n",
            " [9.99999977e-01 2.33502841e-08]\n",
            " [2.31483804e-01 7.68516196e-01]\n",
            " [6.96536569e-01 3.03463431e-01]\n",
            " [9.99999949e-01 5.14009337e-08]\n",
            " [9.97475861e-01 2.52413920e-03]\n",
            " [9.99998131e-01 1.86922937e-06]\n",
            " [9.46911482e-01 5.30885183e-02]\n",
            " [9.63126877e-01 3.68731228e-02]\n",
            " [9.99997065e-01 2.93472107e-06]\n",
            " [2.31483804e-01 7.68516196e-01]\n",
            " [9.98508284e-01 1.49171550e-03]\n",
            " [8.14974171e-01 1.85025829e-01]\n",
            " [9.99984405e-01 1.55947217e-05]\n",
            " [9.99999932e-01 6.84807439e-08]\n",
            " [2.14985850e-01 7.85014150e-01]\n",
            " [9.99999982e-01 1.84500762e-08]\n",
            " [9.99995439e-01 4.56073326e-06]\n",
            " [9.88165455e-01 1.18345447e-02]\n",
            " [9.99998333e-01 1.66650022e-06]\n",
            " [3.39969714e-01 6.60030286e-01]\n",
            " [9.99999992e-01 8.21345912e-09]\n",
            " [9.99999985e-01 1.45216859e-08]\n",
            " [8.70636931e-01 1.29363069e-01]\n",
            " [2.82581884e-01 7.17418116e-01]\n",
            " [9.99612985e-01 3.87015061e-04]\n",
            " [9.99999702e-01 2.97563871e-07]\n",
            " [9.99999961e-01 3.88040006e-08]\n",
            " [9.70293809e-01 2.97061913e-02]\n",
            " [9.99399614e-01 6.00386278e-04]\n",
            " [5.30542251e-01 4.69457749e-01]\n",
            " [9.99999998e-01 1.94413272e-09]\n",
            " [9.99992167e-01 7.83254781e-06]\n",
            " [9.99999831e-01 1.69378861e-07]\n",
            " [3.39969714e-01 6.60030286e-01]\n",
            " [9.80101513e-01 1.98984873e-02]\n",
            " [9.99999733e-01 2.66624604e-07]\n",
            " [9.99999861e-01 1.38929355e-07]\n",
            " [2.82581884e-01 7.17418116e-01]]\n",
            "(100000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDFItbHjFxXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "16229b3a-185c-49e7-c50b-5641bd4eb8f2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "ela = np.mean([8.1,20.47,29.11])\n",
        "l2 = np.mean([23.8,28.03,15.47])\n",
        "\n",
        "print(\"the score grade of an elastic net of our above problem is: {}\".format(ela))\n",
        "print(\"the score grade of an l2 of our above problem is:{}\".format(l2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the score grade of an elastic net of our above problem is: 19.226666666666667\n",
            "the score grade of an l2 of our above problem is:22.433333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}